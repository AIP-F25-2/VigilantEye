{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69aeb65f-c53e-4b1b-8734-37b111bb3207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\okpat\\appdata\\roaming\\python\\python313\\site-packages (4.56.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\okpat\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\okpat\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.35.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\okpat\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\okpat\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\okpat\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\okpat\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\okpat\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\okpat\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\okpat\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\okpat\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\okpat\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\okpat\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\okpat\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\okpat\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\okpat\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\okpat\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478102b9-976e-43cf-8234-b6ba14c2e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, render_template_string\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "from faster_whisper import WhisperModel\n",
    "from tempfile import NamedTemporaryFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1fc15e0-7612-424b-934b-78df0f84e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b03ddfe-d468-401f-b38a-4995d7b88c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf827c01-79b9-4412-b518-4ec615d9a8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e957690f-f31c-4ca7-9960-964e346630b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73cc9295246434c9948d8f2f10ae73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load BLIP2 model and processor once at startup\n",
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-flan-t5-xl\")\n",
    "blip2_model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-flan-t5-xl\")\n",
    "\n",
    "# Load Whisper model once at startup\n",
    "MODEL_SIZE = \"base\"\n",
    "DEVICE = \"cpu\"  # Change to \"cuda\" if GPU available\n",
    "whisper_model = WhisperModel(MODEL_SIZE, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc4d783c-6908-4a33-8b54-20317e8334d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML templates\n",
    "HOME_HTML = \"\"\"\n",
    "<!doctype html>\n",
    "<title>Multi-Modal Flask App</title>\n",
    "<h1>Welcome to the Multi-Modal Flask App</h1>\n",
    "<ul>\n",
    "  <li><a href=\"/describe\">Describe an Image</a></li>\n",
    "  <li><a href=\"/transcribe\">Transcribe Audio</a></li>\n",
    "</ul>\n",
    "\"\"\"\n",
    "\n",
    "IMAGE_UPLOAD_HTML = \"\"\"\n",
    "<!doctype html>\n",
    "<title>Upload Image</title>\n",
    "<h1>Upload an image for description</h1>\n",
    "<form method=\"POST\" enctype=\"multipart/form-data\">\n",
    "  <input type=\"file\" name=\"image\" accept=\"image/*\" required>\n",
    "  <input type=\"submit\" value=\"Upload\">\n",
    "</form>\n",
    "{% if caption %}\n",
    "  <h2>Caption:</h2>\n",
    "  <p>{{ caption }}</p>\n",
    "{% endif %}\n",
    "<a href=\"/\">Back to Home</a>\n",
    "\"\"\"\n",
    "\n",
    "AUDIO_UPLOAD_HTML = \"\"\"\n",
    "<!doctype html>\n",
    "<title>Upload Audio for Transcription</title>\n",
    "<h1>Upload audio file for speech-to-text transcription</h1>\n",
    "<form method=\"POST\" enctype=\"multipart/form-data\">\n",
    "  <input type=\"file\" name=\"file\" accept=\"audio/*\" required>\n",
    "  <input type=\"submit\" value=\"Upload & Transcribe\">\n",
    "</form>\n",
    "{% if language %}\n",
    "  <h3>Detected Language: {{ language }} (Probability: {{ language_prob }})</h3>\n",
    "  <h3>Full Transcript:</h3>\n",
    "  <p>{{ transcript }}</p>\n",
    "{% endif %}\n",
    "<a href=\"/\">Back to Home</a>\n",
    "\"\"\"\n",
    "\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template_string(HOME_HTML)\n",
    "\n",
    "@app.route(\"/describe\", methods=[\"GET\", \"POST\"])\n",
    "def describe():\n",
    "    caption = None\n",
    "    if request.method == \"POST\":\n",
    "        if 'image' not in request.files:\n",
    "            caption = \"No image file provided.\"\n",
    "        else:\n",
    "            image_file = request.files['image']\n",
    "            try:\n",
    "                image = Image.open(image_file.stream).convert(\"RGB\")\n",
    "                inputs = processor(images=image, return_tensors=\"pt\")\n",
    "                generated_ids = blip2_model.generate(**inputs)\n",
    "                caption = processor.decode(generated_ids[0], skip_special_tokens=True)\n",
    "            except Exception as e:\n",
    "                caption = f\"Error processing image: {str(e)}\"\n",
    "    return render_template_string(IMAGE_UPLOAD_HTML, caption=caption)\n",
    "\n",
    "@app.route(\"/transcribe\", methods=[\"GET\", \"POST\"])\n",
    "def transcribe():\n",
    "    language = None\n",
    "    language_prob = None\n",
    "    transcript = None\n",
    "    if request.method == \"POST\":\n",
    "        if \"file\" not in request.files:\n",
    "            transcript = \"No file part.\"\n",
    "        else:\n",
    "            file = request.files[\"file\"]\n",
    "            if file.filename == \"\":\n",
    "                transcript = \"No selected file.\"\n",
    "            else:\n",
    "                try:\n",
    "                    with NamedTemporaryFile(suffix=\".wav\") as temp_audio:\n",
    "                        file.save(temp_audio.name)\n",
    "                        segments, info = whisper_model.transcribe(temp_audio.name, beam_size=5)\n",
    "                        segments = list(segments)\n",
    "                        full_text = \" \".join(seg.text.strip() for seg in segments)\n",
    "                        language = info.language\n",
    "                        language_prob = f\"{info.language_probability:.2f}\"\n",
    "                        transcript = full_text\n",
    "                except Exception as e:\n",
    "                    transcript = f\"Error transcribing audio: {str(e)}\"\n",
    "    return render_template_string(AUDIO_UPLOAD_HTML, language=language, language_prob=language_prob, transcript=transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597c0475-280a-46c8-a58b-af974b6d1c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [26/Sep/2025 11:31:53] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Sep/2025 11:31:53] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [26/Sep/2025 11:31:55] \"GET /describe HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Sep/2025 11:31:56] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Sep/2025 11:31:57] \"GET /transcribe HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Sep/2025 11:31:58] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Sep/2025 11:32:20] \"GET /describe HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Sep/2025 11:32:21] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Sep/2025 11:32:21] \"GET /transcribe HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Sep/2025 11:32:22] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4489daa1-4e41-46fc-b05c-10938157e3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
