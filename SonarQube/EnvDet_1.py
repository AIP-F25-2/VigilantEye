# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qZNnSjn1sGbRAsGQhwM0y2JcntheEyv4
"""

import os, io, json, requests, datetime as _dt, re
from typing import Optional, List, Dict, Any
from PIL import Image
from IPython.display import display
from google import genai
from google.genai.types import Content, Part

GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY") or "AIzaSyDTO982vSAI0BwYJk6-I_dBkj9tYTO1xrk"
client = genai.Client(api_key=GOOGLE_API_KEY)

ALERT_THRESHOLD = "medium"
_SEV_ORDER = {"low":0, "medium":1, "high":2, "critical":3}
def _show_image(img_bytes: bytes, max_side=768):
    img = Image.open(io.BytesIO(img_bytes)).convert("RGB")
    w, h = img.size
    s = max_side / max(w, h)
    if s < 1:
        img = img.resize((int(w*s), int(h*s)))
    display(img)

def _relaxed_json(s: str) -> dict:
    s = (s or "").strip()
    try:
        return json.loads(s)
    except Exception:
        l, r = s.find("{"), s.rfind("}")
        if l != -1 and r != -1 and r > l:
            try: return json.loads(s[l:r+1])
            except Exception: pass
    return {"raw": s}

def _bump(cur: str, nxt: str) -> str:
    return max(cur, nxt, key=lambda x: _SEV_ORDER.get(x, 0))

# --- Situation refinement to avoid defaulting to "crime scene investigation"
def _refine_situation(caption: str, objects: List[str], environment: List[str], proposed: str) -> str:
    c = (caption or "").lower()
    objs = {o.lower() for o in (objects or [])}
    envs = {e.lower() for e in (environment or [])}

    # Strong evidence for real CSI (forensics), else do not choose CSI
    if any(k in c for k in ["police tape","crime scene tape","evidence marker","forensic","evidence bag","forensics","csi","chalk outline"]):
        return "crime scene investigation"

    # Robbery / hold-up: teller/counter + mask/hoodie/gloves/gun/note/cash bag
    if ({"teller","bank","counter","cashier"} & (objs | set(c.split()))) and \
       ({"mask","hoodie","gloves","gun","note","bag"} & (objs | set(c.split()))):
        return "robbery/hold-up in progress"

    # Fire / smoke
    if {"fire","smoke","flames"} & (objs | set(c.split())):
        return "fire emergency"

    # Medical
    if {"ambulance","paramedic","stretcher"} & objs:
        return "medical emergency"

    # Traffic stop
    if {"police car","police"} & objs and any(k in c for k in ["pulled over","driver window","traffic stop"]):
        return "routine traffic stop"

    # Vehicle towing
    if {"tow truck","tow-truck"} & objs:
        return "vehicle towing"

    # Accident
    if any(k in c for k in ["accident","crash","collision"]) or {"damaged car","airbag"} & objs:
        return "accident/traffic collision"

    # Protest
    if ("crowd" in objs or "many people" in c) and ({"sign","banner","megaphone"} & (objs | set(c.split()))):
        return "protest/crowd control"

    # Construction
    if {"cone","barrier","hi-vis vest","helmet"} & objs or any(k in c for k in ["construction","maintenance","roadwork"]):
        return "construction/maintenance"

    # Retail transaction or normal street scene
    if {"counter","cashier","checkout"} & (objs | set(c.split())) and not ({"gun","mask","hoodie","gloves"} & (objs | set(c.split()))):
        return "retail transaction"
    if "street" in envs and not ({"police","ambulance","fire truck","smoke","fire"} & objs):
        return "normal street scene"

    # Otherwise accept model's suggestion (normalized)
    return proposed or "other"

def _rule_based_bump(caption: str, objects: List[str], environment: List[str], weather: List[str]):
    c = (caption or "").lower()
    objs = {o.lower() for o in (objects or [])}
    envs = {e.lower() for e in (environment or [])}
    wx   = {w.lower() for w in (weather or [])}
    sev, reasons = "low", []

    # Hard hazards
    if {"gun","knife","weapon","explosion","fire","smoke","blood"} & objs or \
       any(k in c for k in ["gun","knife","weapon","explosion","fire","smoke","blood"]):
        return "critical", ["hazard (weapon/fire/smoke) detected (rule)"]

    # Responders / cordon / collision
    if {"police","police officer","police officers","ambulance","fire truck","firetruck","tow truck","tow-truck"} & objs:
        sev = _bump(sev, "medium"); reasons.append("emergency/traffic intervention (rule)")
    if any(k in c for k in ["accident","crash","collision","crime scene","cordon","taped area","evacuate","investigation"]):
        sev = _bump(sev, "high"); reasons.append("incident indicated (rule)")

    # Weather risk
    if {"stormy","flood","snowy"} & wx:
        sev = _bump(sev, "high"); reasons.append("severe weather (rule)")
    elif {"rainy","foggy","hazy","night","overcast"} & wx:
        sev = _bump(sev, "medium"); reasons.append("low-visibility weather (rule)")

    # Crowd near traffic
    if ("crowd" in objs or "many people" in c) and ({"car","bus","truck"} & objs or "traffic" in c or "street" in envs):
        sev = _bump(sev, "medium"); reasons.append("crowd near traffic (rule)")

    # Construction / maintenance
    if any(k in c for k in ["construction","maintenance","roadwork"]) or {"barrier","cone"} & objs:
        sev = _bump(sev, "medium"); reasons.append("construction/maintenance activity (rule)")

    return sev, list(dict.fromkeys(reasons))

# --- ANSI colors for notebook text
RED     = "\033[31m"
GREEN   = "\033[32m"
ORANGE  = "\033[33m"  # yellow ≈ orange in ANSI
RESET   = "\033[0m"

def _color_for(severity: str, is_abnormal: bool, triggered: bool) -> str:
    sev = (severity or "low").lower()
    if triggered or is_abnormal or sev in ("high","critical"):
        return RED
    if sev == "medium":
        return ORANGE
    return GREEN

def _colorize(val: str, color: str) -> str:
    return f"{color}{val}{RESET}"

def _print_color_dict(payload: Dict[str,Any]):
    """
    Prints a dict-like block where key variables are colorized:
      - 'situation', 'severity', 'is_abnormal', 'alert_triggered' (and reason) use severity color.
      - others are plain.
    """
    color = _color_for(payload.get("severity"), payload.get("is_abnormal"), payload.get("alert_triggered"))

    # Compose dict-like message
    lines = []
    def kv(k, v, colored=False):
        if isinstance(v, list):
            v_str = "[" + ", ".join([repr(x) for x in v]) + "]"
        elif isinstance(v, str):
            v_str = repr(v)
        else:
            v_str = repr(v)
        if colored:
            v_str = _colorize(v_str, color)
        lines.append(f" '{k}': {v_str},")

    print("{")
    kv("image_url", payload.get("image_url"))
    kv("caption", payload.get("caption"))
    kv("objects", payload.get("objects", []))
    kv("environment", payload.get("environment", []))
    kv("weather", payload.get("weather", []))
    kv("situation", payload.get("situation"), colored=True)
    kv("is_abnormal", payload.get("is_abnormal"), colored=True)
    kv("severity", payload.get("severity"), colored=True)
    kv("reasons", payload.get("reasons", []), colored=True)
    kv("confidence", payload.get("confidence"))
    kv("explanation", payload.get("explanation"))
    kv("alert_triggered", payload.get("alert_triggered"), colored=True)
    kv("alert_trigger_reason", payload.get("alert_trigger_reason"), colored=True)
    # trim trailing comma on last line visually (optional)
    for i, ln in enumerate(lines):
        if i == len(lines) - 1:
            ln = ln[:-1]  # drop comma
        print(ln)
    print("}")

# --- Core pipeline
def analyze_image(image_url: Optional[str] = None,
                  image_file: Optional[bytes] = None,
                  mime_type: str = "image/jpeg",
                  model_name: str = "gemini-2.0-flash",
                  min_words: int = 25) -> Dict[str, Any]:

    assert image_url or image_file, "Provide image_url or image_file bytes."
    # Fetch bytes
    if image_url:
        rr = requests.get(image_url, timeout=30)
        rr.raise_for_status()
        img_bytes = rr.content
    else:
        img_bytes = image_file

    # Show image
    _show_image(img_bytes)

    # Prompt with expanded taxonomy and explicit CSI criteria
    taxonomy = [
        "normal street scene","retail transaction","suspicious behavior","robbery/hold-up in progress",
        "routine traffic stop","vehicle towing","accident/traffic collision",
        "crime scene investigation","medical emergency","fire emergency",
        "protest/crowd control","construction/maintenance","other"
    ]
    env_hint = ["indoor","outdoor","street","office","park","residential","warehouse",
                "hospital","lab","kitchen","parking lot","school","shop","airport","train station","industrial"]
    weather_hint = ["sunny","cloudy","overcast","rainy","snowy","foggy","hazy","stormy","night","dusk","dawn"]

    prompt = (
        "You are a vision safety analyst. Look at the image and return STRICT JSON ONLY with keys:\n"
        '"caption": short string,\n'
        '"objects": 3–10 salient object nouns,\n'
        '"environment": 1–5 from ' + json.dumps(env_hint) + ',\n'
        '"weather": 0–3 from ' + json.dumps(weather_hint) + ',\n'
        '"situation_type": ONE of ' + json.dumps(taxonomy) + ".\n"
        "Only choose 'crime scene investigation' if POLICE TAPE, EVIDENCE MARKERS, FORENSIC SUITS, or EVIDENCE BAGGIES are visible.\n"
        "Choose 'robbery/hold-up in progress' if a masked/hooded/gloved person is interacting with a teller/cashier/counter, with implied threat (weapon or demand note or cash bag).\n"
        "Be conservative and pick the most direct match.\n"
        '"is_abnormal": boolean (true if alert-worthy; false if routine/normal),\n'
        '"severity": one of ["low","medium","high","critical"],\n'
        '"reasons": 1–4 short phrases,\n'
        '"confidence": number 0..1 with two decimals,\n'
        '"explanation": a single paragraph of 25–60 words explaining what is happening and why it matters.\n'
        "No markdown, no extra words—JSON only."
    )

    parts = [Part(text=prompt), Part(inline_data={"mime_type": mime_type, "data": img_bytes})]
    res = client.models.generate_content(
        model=model_name,
        contents=Content(parts=parts),
        config={"temperature": 0.1, "max_output_tokens": 420}
    )
    data = _relaxed_json(res.text)

    # Normalize
    caption = (data.get("caption") or "").strip()
    objects = [str(o).strip() for o in (data.get("objects") or []) if str(o).strip()][:10]
    environment = [str(e).strip() for e in (data.get("environment") or []) if str(e).strip()][:5]
    weather = [str(w).strip() for w in (data.get("weather") or []) if str(w).strip()][:3]
    situation_model = (data.get("situation_type") or "other").strip()
    is_abnormal = bool(data.get("is_abnormal", False))
    severity = (data.get("severity") or "low").strip().lower()
    reasons = [str(r).strip() for r in (data.get("reasons") or []) if str(r).strip()][:4]
    try:
        confidence = float(data.get("confidence", 0.70))
    except Exception:
        confidence = 0.70
    explanation = (data.get("explanation") or "").strip().replace("\n", " ")

    # Ensure paragraph length
    if len(explanation.split()) < min_words:
        expand = f"Rewrite to at least {min_words} words (<= 70), clear and specific, no markdown: {explanation}"
        res2 = client.models.generate_content(
            model=model_name,
            contents=Content(parts=[Part(text=expand)]),
            config={"temperature": 0.1, "max_output_tokens": 200}
        )
        ex2 = (res2.text or "").strip().replace("\n", " ")
        if len(ex2.split()) >= min_words:
            explanation = ex2

    # Refine situation to avoid CSI overuse
    situation = _refine_situation(caption, objects, environment, situation_model)

    # Rule-based bump for severity/abnormal
    sev_rule, rule_reasons = _rule_based_bump(caption, objects, environment, weather)
    if _SEV_ORDER.get(sev_rule,0) > _SEV_ORDER.get(severity,0):
        severity = sev_rule
        reasons = (reasons + rule_reasons)[:4]
    # Minimal mapping: mark abnormal for obviously risky situations
    abnormal_situations = {
        "robbery/hold-up in progress","accident/traffic collision","fire emergency",
        "medical emergency","crime scene investigation","protest/crowd control"
    }
    is_abnormal = is_abnormal or (situation in abnormal_situations) or (severity in {"medium","high","critical"})

    # Alert decision
    trigger = _SEV_ORDER.get(severity,0) >= _SEV_ORDER.get(ALERT_THRESHOLD,1) or is_abnormal
    alert_reason = "severity-threshold" if _SEV_ORDER.get(severity,0) >= _SEV_ORDER.get(ALERT_THRESHOLD,1) else "abnormal-flag"

    # Build payload
    payload = {
        "ts": _dt.datetime.utcnow().isoformat() + "Z",
        "image_url": image_url if image_url else None,
        "caption": caption,
        "objects": objects,
        "environment": environment,
        "weather": weather,
        "situation": situation,
        "is_abnormal": bool(is_abnormal),
        "severity": severity,
        "reasons": reasons,
        "confidence": round(confidence, 2),
        "explanation": explanation,
        "alert_triggered": bool(trigger),
        "alert_trigger_reason": alert_reason
    }
    return payload

def run(image_url: Optional[str] = None, image_file: Optional[bytes] = None):
    result = analyze_image(image_url=image_url, image_file=image_file)
    # show explanation paragraph first (plain)
    print(result["explanation"], end="\n\n")
    # then print the colorized dict-like message
    _print_color_dict(result)
    return result

run(image_url="https://tse2.mm.bing.net/th/id/OIP.RiWLTYy7DWjuB9wm71v21gHaEK?pid=Api&P=0&h=180")

# Example:
# run(image_url="--")

# Or upload:
# from google.colab import files
# up = files.upload()
# if up:
#     fn = next(iter(up))
#     with open(fn,"rb") as f:
#         img_b = f.read()
#     run(image_file=img_b)

